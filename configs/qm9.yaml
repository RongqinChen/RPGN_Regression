batch_size: 128
num_workers: 6
lr: 1e-3
min_lr: 1e-6
l2_wd: 1e-5
num_epochs: 350
num_warmup_epochs: 20
emb_channels: 16
hidden_channels: 96
num_layers: 8
mlp_depth: 1
norm_type: Batch
drop_prob: 0.0
graph_pool: mean
jumping_knowledge: last
task_type: graph_regression
num_task: 1
runs: 10
